---
title: "Response time correction of Contros HydroC pCO~2~ data"
author: "Jens Daniel Müller"
date:  "`r format(Sys.time(), '%d %B, %Y')`"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---


```{r global_options, include = FALSE}
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
```


```{r packages}
library(tidyverse)
library(seacarb)
library(data.table)
library(broom)
library(lubridate)
```

# Sensitivity considerations

A change in DIC of 1 µmol kg^-1^ corresponds to a change in pCO~2~ of around 1 µatm, in the Central Baltic Sea at a pCO~2~ of around 100 µatm (summertime conditions).

```{r sensitivity_estimate, fig.cap="pCO~2~ sensitivity to changes in DIC."}

df <- data.frame(cbind(
  (c(1720)),
  (c(7))))

Tem <- seq(5,25,5)
pCO2<-seq(50,500,20)

df<-merge(df, Tem)
names(df) <- c("AT", "S", "Tem")  

df<-merge(df, pCO2)
names(df) <- c("AT", "S", "Tem", "pCO2")  

df<-data.table(df)
df$AT<-df$AT*1e-6

df$DIC<-carb(flag=24, var1=df$pCO2, var2=df$AT, S=df$S, T=df$Tem, k1k2="m10", kf="dg", pHscale="T")[,16]
df$pCO2.corr<-carb(flag=15, var1=df$AT, var2=df$DIC, S=df$S, T=df$Tem, k1k2="m10", kf="dg", pHscale="T")[,9]

df$pCO2.2<-df$pCO2.corr + 25
df$DIC.2<-carb(flag=24, var1=df$pCO2.2, var2=df$AT, S=df$S, T=df$Tem, k1k2="m10", kf="dg", pHscale="T")[,16]


df$ratio<-(df$pCO2.2-df$pCO2.corr)/(df$DIC.2*1e6-df$DIC*1e6)

df %>% 
  ggplot(aes(pCO2, ratio, col=as.factor(Tem)))+
  geom_line()+
  scale_color_viridis_d(option = "C",name="Tem [°C]")+
  labs(x=expression(pCO[2]~(µatm)), y=expression(Delta~pCO[2]~"/"~Delta~DIC~(µatm~µmol^{-1}~kg)))+
  scale_y_continuous(limits = c(0,8), breaks = seq(0,10,1))

rm(df, Tem, pCO2)

```


# HydroC sensor settings

The sensor was first run with a low power pump (1W), later and for most parts of the expedition with a stronger (8W) pump. Pumps were switched between recordings (data file: SD_datafile_20180718_170417CO2-0618-001.txt):  

* 2018-07-17;13:08:34
* 2018-07-17;13:08:35

Logging frequency for all measurement modes (Measure, Zero, Flush) was set to:  

10 sec for all recordings including SD_datafile_20180714_073641CO2-0618-001.txt  

Increase to 2 sec in SD_datafile_20180717_121052CO2-0618-001.txt at:  

* 2018-07-14;07:52:02
* 2018-07-14;07:52:12
* 2018-07-14;07:52:14

Increase to 2 sec in SD_datafile_20180718_170417CO2-0618-001 at:  

* 2018-07-17;12:27:25
* 2018-07-17;12:27:27
* 2018-07-17;12:27:28

# Response time determination

Response times were determined by fitting a nonlinear least-squares model with the `nls` function as described [here](http://douglas-watson.github.io/post/2018-09_exponential_curve_fitting/) by Douglas Watson.

* Flush period length: variable
* Flush period restricted to equilibration phase, avoiding initial gas mixing effects occuring at the start of each Flush period
* only completet Flush periods (duration > 500 sec) included


```{r response_determination_data_preparation}

# Read and prepare data

df <- read_csv(here::here("data/_merged_data_files",
                          "BloomSail_CTD_HydroC_Contros_clean.csv"),
               col_types = cols(ID = col_character(),
                                pCO2_analog = col_double(),
                                pCO2 = col_double(),
                                Zero = col_factor(),
                                Flush = col_factor(),
                                Zero_ID = col_integer(),
                                duration = col_double(),
                                mixing = col_character()))

df <- df %>%
  select(date_time, ID, dep, tem, Flush, pCO2, Zero_ID, duration, mixing)

df <- df %>%
  filter(Flush == 1, mixing == "equilibration")

df <- df %>% 
  group_by(Zero_ID) %>% 
  mutate(duration = duration- min(duration),
         max_duration = max(duration)) %>% 
  ungroup() %>% 
  filter(max_duration >= 500) %>% 
  select(-max_duration)

```

An example plot for a `nls` model fitted to pCO~2~ observations during a Flush phase is shown below.


```{r response_determination_example_plot, fig.cap="Example response time determination by non-linear least squares fit to the pCO~2~ recovery signal after zeroing. The vertical line indicates the determined response time tau."}

# Plot example Flush period with exponential fit ----------------------

i <- 95

df_ID <- df %>%
  filter(Zero_ID == i, duration <= 300)

fit <-
df_ID %>%
  nls(pCO2 ~ SSasymp(duration, yf, y0, log_alpha), data = .)

tau <- as.numeric(exp(-tidy(fit)[3,2]))
pCO2_end <- as.numeric(tidy(fit)[1,2])
pCO2_start <- as.numeric(tidy(fit)[2,2])
dpCO2 = pCO2_end - pCO2_start
mean_abs_resid <- mean(abs(resid(fit)))

augment(fit) %>%
  ggplot(aes(duration, pCO2))+
  geom_point()+
  geom_line(aes(y = .fitted))+
  geom_vline(xintercept = tau)+
  geom_hline(yintercept = pCO2_start + 0.63 *(dpCO2))+
  labs(y=expression(pCO[2]~(µatm)), x="Duration of Flush period (s)")

rm(df_ID, fit, i, tau, dpCO2, pCO2_end, pCO2_start)
```

```{r set_flush_duration_intervals}

duration_intervals <- seq(150,500,50)

```



In the following we determine the response time tau for all zeroings and for total durations of:  
`r duration_intervals` secs


```{r all_response_times}

# Plot all individual Flush periods with exponential fit ----------------------

pdf(file=here::here("output/Plots/response_time",
    "RT_determination.pdf"), onefile = TRUE, width = 7, height = 4)

for (i in unique(df$Zero_ID)) {
  for (max_duration in duration_intervals) {
    
    df_ID <- df %>%
      filter(Zero_ID == i, duration <= max_duration)
    
    fit <- 
      try(
      df_ID %>%
          nls(pCO2 ~ SSasymp(duration, yf, y0, log_alpha), data = .),
      TRUE)
    
    if (class(fit) == "nls"){
    
      tau <- as.numeric(exp(-tidy(fit)[3,2]))
      pCO2_end <- as.numeric(tidy(fit)[1,2])
      pCO2_start <- as.numeric(tidy(fit)[2,2])
      dpCO2 = pCO2_end - pCO2_start
      mean_abs_resid <- mean(abs(resid(fit))/pCO2_end)*100
      
      temp <- as_tibble(bind_cols(Zero_ID = i, duration = max_duration, tau = tau, resid = mean_abs_resid))
      
      if (exists("tau_df")){tau_df <- bind_rows(tau_df, temp)}
        else {tau_df <- temp}
      
      print(
      augment(fit) %>%
        ggplot(aes(duration, pCO2))+
        geom_point()+
        geom_line(aes(y = .fitted))+
        geom_vline(xintercept = tau)+
        geom_hline(yintercept = pCO2_start + 0.63 *(dpCO2))+
        labs(y=expression(pCO[2]~(µatm)), x="Duration of Flush period (s)",
             title = paste("Zero_ID: ", i, "Mean absolute residual (%): ", round(mean_abs_resid*100, 2)))+
        xlim(0,600)
      )
      
    }
  }
}

dev.off()

rm(df_ID, fit, i, tau, dpCO2, pCO2_end, pCO2_start, temp, max_duration, mean_abs_resid)

# Plot individual Flush periods with linearized response variable  --------


# for (i in unique(df$Zero_ID)) {
# 
# #i <- 50
# df_ID <- df %>%
#   filter(Zero_ID == i,
#          mixing == "equilibration")
# 
# mean_pCO2 <- df_ID %>% 
#   slice((n()-4) : n()) %>% 
#   summarise(mean_pCO2 = mean(pCO2))
# 
# df_ID <- full_join(df_ID, mean_pCO2) %>% 
#   mutate(dpCO2 = max(pCO2) - pCO2,
#          ln_dpCO2 = log(dpCO2))
# 
# 
# df_ID %>%
#   ggplot(aes(duration_equi, ln_dpCO2))+
#   geom_point()+
#   geom_smooth(method = "lm")+
#   theme_bw()
# 
# # augment(fit) %>%
# #   ggplot(aes(duration_equi, pCO2))+
# #   geom_point()+
# #   geom_line(aes(y = .fitted))+
# #   geom_vline(xintercept = tau)
# 
# ggsave(here::here("/Plots/TinaV/Sensor/HydroC_diagnostics/Response_time_fits",
#                   paste(i,"_Zero_ID_HydroC_RT_linear.jpg", sep="")),
#          width = 10, height = 4)
# }

```

A pdf with plots of all individual response time fits can be accessed [here](https://github.com/jens-daniel-mueller/BloomSail/tree/master/output){target="_blank"}


```{r set_tau_and_residual_thresholds}

tau_high <- 120
tau_low <- 20
resid_limit <- 1

tau_df_sub <- tau_df %>% 
  filter(resid < resid_limit, tau > tau_low, tau < tau_high)

tau_total <- nrow(tau_df)
tau_sub <- nrow(tau_df_sub)

```


# Outcome

Response times were determined sucessfully determined by `nls` in a total number of `r tau_total` cases.  
Restriction of the determined tau values to those falling between `r tau_low` and `r tau_high` seconds and corresponding to a fit with a mean absolute residual below `r resid_limit` % of the final equilibrium pCO~2~, results in `r tau_sub` remaining tau values (`r round(100*tau_sub/tau_total, 1)` %).



```{r plot_response_times}

tau_df_sub %>% 
  ggplot(aes(resid))+
  geom_histogram()+
  facet_wrap(~duration)

tau_df_sub %>% 
  ggplot(aes(Zero_ID, tau, col=duration))+
  geom_point()+
  scale_color_viridis_c()

tau_df_sub %>% 
  group_by(Zero_ID) %>% 
  mutate(d_tau = tau - mean(tau)) %>% 
  ggplot(aes(duration, d_tau))+
  geom_violin(aes(group=duration))+
  geom_point()

tau_df_sub %>% 
  group_by(Zero_ID) %>% 
  mutate(d_tau = tau - mean(tau)) %>% 
  ggplot(aes(duration, d_tau))+
  geom_smooth()+
  geom_point()+
  facet_wrap(~Zero_ID)

tau_df_sub %>% 
  group_by(duration) %>% 
  mutate(n_tau = n()) %>% 
  ggplot(aes(duration, n_tau))+
  geom_point()

```


```{r response_determination, eval=FALSE, include=FALSE}

# Response time fitting ---------------------------------------------------

RT <- df %>% 
  filter(duration <= 300) %>% 
  group_by(Zero_ID) %>% 
  do(fit = nls(pCO2 ~ SSasymp(duration, yf, y0, log_alpha), data = .)) %>% 
  tidy(fit) %>% 
  select(Zero_ID, term, estimate) %>% 
  spread(term, estimate) %>% 
  select(1,2) %>% 
  mutate(tau = exp(-log_alpha))


# Residuals from fit ------------------------------------------------------

augmented <- df %>% 
  group_by(Zero_ID) %>% 
  do(fit = nls(pCO2 ~ SSasymp(duration_equi, yf, y0, log_alpha), data = .)) %>% 
  augment(fit)

# qplot(duration_equi, pCO2_corr, data = augmented, geom = 'point', colour = as.factor(Zero_ID)) +
#   geom_line(aes(y=.fitted))
# 
# qplot(duration_equi, .resid, data = augmented, geom = 'point', colour = as.factor(Zero_ID))

augmented_sum <- augmented %>% 
  group_by(Zero_ID) %>% 
  summarise(mean_resid = mean(abs(.resid)),
            mean_resid_rel = mean(abs(.resid))/max(pCO2),
            max_pCO2_corr = max(pCO2))

# Standard error of tau ---------------------------------------------------

St_Err <- df %>% 
  filter(mixing == "equilibration") %>% 
  group_by(Zero_ID) %>% 
  do(fit = nls(pCO2 ~ SSasymp(duration_equi, yf, y0, log_alpha), data = .)) %>% 
  tidy(fit) %>% 
  select(Zero_ID, term, std.error) %>% 
  spread(term, std.error) %>% 
  select(1,2) %>% 
  rename(tau_st_err = log_alpha)


# Merge RT, mean residuals and St error -----------------------------------

RT <- full_join(RT, augmented_sum)
RT <- full_join(RT, St_Err)

rm(augmented, augmented_sum, St_Err)



# Identify residual threshold ---------------------------------------------

# RT %>% 
#   ggplot(aes(mean_resid_rel, Zero_ID, label=Zero_ID)) +
#   geom_point(shape=21)+
#   scale_fill_viridis_c()+
#   geom_label()

RT %>% 
  filter(mean_resid_rel >= 0.0065)

# RT %>% 
#   filter(mean_resid_rel < 0.0065) %>% 
#   ggplot(aes(Zero_ID, tau, label=round(mean_resid_rel,4))) +
#   geom_label(data=RT, aes(Zero_ID, tau, label=round(mean_resid_rel,4)), col="red") +
#   geom_point(shape=21)+
#   scale_fill_viridis_c()+
#   geom_label()

RT %>% 
  filter(mean_resid_rel < 0.0065) %>% 
  ggplot(aes(Zero_ID, tau))+
  geom_point()



# Mean tau ----------------------------------------------------------------

max(unique(df[df$date_time < ymd_hms("2018-07-17;13:08:34"),]$Zero_ID))
unique(df[df$date_time > ymd_hms("2018-07-17;13:08:34"),]$Zero_ID)

RT %>% 
  filter(mean_resid_rel < 0.0065) %>% 
  mutate(pump_power = if_else(Zero_ID <= 20, "1W", "8W")) %>% 
  group_by(pump_power) %>% 
  summarise(tau = mean(tau))

```



## This approach

## Contros in-house

## Comparison

# Pre-smoothing

# Response time correction

# Post-smoothing

# Response time optimization

# Open tasks / questions

- Compare Contros and own response time estimates
- Compare differnt response time correction methods (Bittig vs. Fiedler, Miloshevich, Fietzek)
- Test impact of duration for response time estimation on final mean response time
- Test impact of selection criterion for "good" response time estimates on final mean response time
- Check results from field response time experiment (high zeroing frequency)
- Why does nls model failure increase with higher fit duration
